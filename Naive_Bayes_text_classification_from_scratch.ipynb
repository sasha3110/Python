{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes text classification from scratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "peAsa0rzT8mM",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x-KdQRpXT_ND",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/ML')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZcogLXuZUBrY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "genres = ['DETECT', 'FANTAST', 'RELIGION', 'TALES']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0aVQhEuvFeG2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "path = 'ENGLISH/'\n",
        "texts = {}\n",
        "\n",
        "for genre in genres:\n",
        "  texts[genre] = {}\n",
        "  inpath = path + genre\n",
        "  for filename in glob.glob(os.path.join(inpath, '*.TXT')):    \n",
        "    try:\n",
        "      with open(filename, 'r', encoding='utf-8') as f:      \n",
        "        texts[genre][filename.split('/')[-1]] = ''.join(f.readlines())\n",
        "      print(filename)\n",
        "    except:      \n",
        "      with open(filename, 'r', encoding='latin-1') as f:      \n",
        "        texts[genre][filename.split('/')[-1]] = ''.join(f.readlines())\n",
        "      print(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lAGvXn8aFhs2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1db97479-6dec-4c96-b05c-0ee38f019491"
      },
      "cell_type": "code",
      "source": [
        "tcount = 0\n",
        "for genre in texts:\n",
        "  print(genre + \" : \" + str(len(texts[genre])))\n",
        "  tcount += len(texts[genre])\n",
        "print('Total : ', str(tcount))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DETECT : 29\n",
            "FANTAST : 75\n",
            "RELIGION : 22\n",
            "TALES : 28\n",
            "Total :  154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MGZ3dtpEFlve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "3fe063ad-54e1-4835-845a-5fbaa96a7261"
      },
      "cell_type": "code",
      "source": [
        "# Split texts to train and test subsets\n",
        "\n",
        "import random\n",
        "\n",
        "train_texts = {}\n",
        "test_texts = {}\n",
        "train_num = 0\n",
        "\n",
        "\n",
        "for genre in texts:\n",
        "  train_texts[genre] = {}\n",
        "  test_texts[genre] = {}\n",
        "  train_num = int(len(texts[genre])*0.8)\n",
        "  train_sample = random.sample(texts[genre].keys(), train_num)\n",
        "  for text in texts[genre]:\n",
        "    if text in train_sample:\n",
        "      train_texts[genre][text] = texts[genre][text]\n",
        "    else:\n",
        "      test_texts[genre][text] = texts[genre][text]\n",
        "\n",
        "      \n",
        "print('Train texts:')      \n",
        "tcount = 0\n",
        "for genre in train_texts:\n",
        "  print(genre + \" : \" + str(len(train_texts[genre])))\n",
        "  tcount += len(train_texts[genre])\n",
        "print('-----')\n",
        "print('Total :', str(tcount))  \n",
        "\n",
        "print('\\n')    \n",
        "\n",
        "print('Test texts:')      \n",
        "tcount = 0\n",
        "for genre in test_texts:\n",
        "  print(genre + \" : \" + str(len(test_texts[genre])))\n",
        "  tcount += len(test_texts[genre])\n",
        "print('-----')\n",
        "print('Total :', str(tcount)) "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train texts:\n",
            "DETECT : 23\n",
            "FANTAST : 60\n",
            "RELIGION : 17\n",
            "TALES : 22\n",
            "-----\n",
            "Total : 122\n",
            "\n",
            "\n",
            "Test texts:\n",
            "DETECT : 6\n",
            "FANTAST : 15\n",
            "RELIGION : 5\n",
            "TALES : 6\n",
            "-----\n",
            "Total : 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gZE7VNFfFtz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "be2cb572-8839-4c95-8f99-b9c39741588c"
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "p_genres = {}\n",
        "for genre in genres:  \n",
        "  p_genres[genre] = math.log((len(texts[genre])) / tcount)\n",
        "p_genres"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DETECT': -0.09844007281325252,\n",
              " 'FANTAST': 0.8517522107365839,\n",
              " 'RELIGION': -0.3746934494414107,\n",
              " 'TALES': -0.13353139262452263}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "wkpPayE1F4Yf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Calculate Likelihood"
      ]
    },
    {
      "metadata": {
        "id": "ipSrKtjhF0Yb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "stopWords = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S6KA0VcPGBvx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lemmatize_all(sentence):\n",
        "    wnl = WordNetLemmatizer()\n",
        "    for word, tag in pos_tag(sentence):\n",
        "        if tag.startswith(\"NN\"):\n",
        "            yield wnl.lemmatize(word, pos='n')\n",
        "        elif tag.startswith('VB'):\n",
        "            yield wnl.lemmatize(word, pos='v')\n",
        "        elif tag.startswith('JJ'):\n",
        "            yield wnl.lemmatize(word, pos='a')\n",
        "        else:\n",
        "            yield word\n",
        "  \n",
        "def clean_text_lemma(text, lemma=True): \n",
        "    ''' \n",
        "    Utility function to clean text by removing links, special characters \n",
        "    using simple regex statements. Also converting words to lemmas.\n",
        "    '''    \n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()    \n",
        "    stripped_text = re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", text).lower().split()\n",
        "    lemma_text = lemmatize_all(stripped_text)\n",
        "    filtered_text = [word for word in lemma_text if word not in stopWords]\n",
        "    join_text = ' '.join(filtered_text)\n",
        "    return join_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rUMVFMfXGGtv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bag(text):\n",
        "  bag = {}\n",
        "  max_count = 0\n",
        "  words = text.split()\n",
        "  \n",
        "  for word in words:      \n",
        "    if word in bag:\n",
        "      bag[word] += 1\n",
        "    else:\n",
        "      bag[word] = 1\n",
        "  \n",
        "  for word in bag:\n",
        "    if bag[word] > max_count:\n",
        "      max_count = bag[word]\n",
        "  \n",
        "   \n",
        "  for word in bag:\n",
        "    bag[word] = (float(bag[word]) / max_count) * 100\n",
        "  \n",
        "  return bag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vxMFKRN6GJyB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clean train text and count words per text\n",
        "\n",
        "p_word = {}\n",
        "for genre in train_texts:\n",
        "  p_word[genre] = {}\n",
        "  for text in train_texts[genre]:    \n",
        "    train_texts[genre][text] = clean_text_lemma(train_texts[genre][text])\n",
        "    p_word[genre][text] = make_bag(train_texts[genre][text])    \n",
        "    print(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "33148jPKGNTV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "45317ebd-99a0-4492-b6ed-b0234706cf68"
      },
      "cell_type": "code",
      "source": [
        "# Gather mean and variance per word per genre\n",
        "import numpy as np\n",
        "p_word_stat = {}\n",
        "\n",
        "for genre in p_word:  \n",
        "  p_word_stat[genre] = {}\n",
        "  \n",
        "  for text in p_word[genre]:   \n",
        "    for word in p_word[genre][text]:     \n",
        "      if word in p_word_stat[genre]:\n",
        "        p_word_stat[genre][word]['values'] = np.append(p_word_stat[genre][word]['values'], p_word[genre][text][word])\n",
        "      else:\n",
        "        p_word_stat[genre][word] = {}\n",
        "        p_word_stat[genre][word]['values'] = np.array([p_word[genre][text][word]])\n",
        "        \n",
        "  for word in p_word_stat[genre]:\n",
        "    if len(p_word_stat[genre][word]['values']) < len(p_word[genre]):      \n",
        "      dif = len(p_word[genre]) - len(p_word_stat[genre][word]['values'])      \n",
        "      p_word_stat[genre][word]['values'] = np.pad(p_word_stat[genre][word]['values'], (0,dif), 'constant')\n",
        "    \n",
        "    p_word_stat[genre][word]['mean'] = p_word_stat[genre][word]['values'].mean()\n",
        "    p_word_stat[genre][word]['var'] = p_word_stat[genre][word]['values'].var()\n",
        "    p_word_stat[genre][word]['std'] = p_word_stat[genre][word]['values'].std()\n",
        "  \n",
        "  print(len(p_word[genre]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23\n",
            "60\n",
            "17\n",
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "znuD5LxiGVYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def calculateProbability(x, mean, stdev):\n",
        "  exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
        "  return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
        "\n",
        "\n",
        "def naive_product(text_bag, class_stats):\n",
        "  naive_p = 1\n",
        "  for word in text_bag:\n",
        "    try:\n",
        "      p = calculateProbability(text_bag[word], class_stats[word]['mean'], class_stats[word]['std'])\n",
        "      p = math.log(p)\n",
        "    except:\n",
        "      p = math.log(2.2250738585072014e-250)\n",
        "      \n",
        "    if not p == 0.0:      \n",
        "      naive_p += p      \n",
        "    else:\n",
        "      naive_p += math.log(2.2250738585072014e-250)\n",
        "      print(naive_p)\n",
        "  return naive_p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZGaqVMKGcW9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(text, priors=p_genres, classes=genres, word_stats=p_word_stat):\n",
        "  predictions = {}\n",
        "  text_lemma = clean_text_lemma(text)\n",
        "  text_bag = make_bag(text_lemma)  \n",
        "  \n",
        "  for genre in classes:\n",
        "    prediction = priors[genre] + naive_product(text_bag, word_stats[genre])\n",
        "    predictions[genre] = prediction\n",
        "  sorted_predictions = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n",
        "  return sorted_predictions "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hLmebxEQGh2O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model accuracy"
      ]
    },
    {
      "metadata": {
        "id": "24iA9nVjGibG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "guessed = 0\n",
        "for genre in test_texts:\n",
        "  print(\"Predict\", genre)\n",
        "  for text in test_texts[genre]:\n",
        "    total += 1\n",
        "    prediction = predict(test_texts[genre][text])\n",
        "    print(prediction)\n",
        "    if prediction[0][0] == genre:\n",
        "      guessed += 1    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7C71xQw9GlH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5019d9e9-1458-43fe-8df2-671ad9552111"
      },
      "cell_type": "code",
      "source": [
        "print(\"Model accuracy:\", \"{0:8.2f}\".format(guessed / total))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy:     0.69\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}